{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Quality Tutorial - Python 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisities\n",
    "You should have worked through:\n",
    "1. The Data Quality Core training module which is a foundation for all data quality training. This will explain the Data Quality Dimensions (like Uniqueness), and how each measure is calculated.\n",
    "2. The Python 1 Tutorial (found in this directory). This will equip you to run all of the data quality functions against dataframes, interpret the output, and export the final report\n",
    "\n",
    "### Prior coding experience required\n",
    "* You should know what pandas dataframes are\n",
    "* You should have some basic python knowledge\n",
    "\n",
    "## Aims of Python 2\n",
    "* To be able to write a data quality config file\n",
    "    * this is one or more text files that define your data quality rules\n",
    "* To be able to run this config file against your dataframe\n",
    "* To write and use a regular expression config file as part of this workflow\n",
    "    * the allows you to store all your regular expressions in one place, and makes the data quality config file more readable\n",
    "* To understand how to obtain a config file directly from a data quality report\n",
    "    * this assists a typical workflow where you might play around with several rules in a notebook, but then want a production-ready config file afterwards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T12:51:52.930536Z",
     "iopub.status.busy": "2025-09-18T12:51:52.930312Z",
     "iopub.status.idle": "2025-09-18T12:51:54.161842Z",
     "shell.execute_reply": "2025-09-18T12:51:54.161271Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from gchq_data_quality import (\n",
    "    DataQualityConfig,\n",
    "    UniquenessRule,\n",
    "    ValidityRegexRule,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's re-use the same dataframe we used in Python 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T12:51:54.164497Z",
     "iopub.status.busy": "2025-09-18T12:51:54.164212Z",
     "iopub.status.idle": "2025-09-18T12:51:54.214616Z",
     "shell.execute_reply": "2025-09-18T12:51:54.213850Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"id\": [1, 2, 3, 3, 5],  # 4 /5 unique\n",
    "        \"name\": [\"John\", \"Jane\", \"Dave\", None, \"Missing\"],  # 1 null value\n",
    "        \"age\": [30, 25, 102, 15, -5],  # a negative age\n",
    "        \"email\": [\n",
    "            \"john@example.com\",\n",
    "            \"jane@example.com\",\n",
    "            \"dave@example\",\n",
    "            \"test@test.com\",\n",
    "            \"alice@example.com\",\n",
    "        ],  # invalid 3rd email\n",
    "        \"category\": [\"A\", \"B\", \"C\", \"D\", \"X\"],\n",
    "        \"score\": [\n",
    "            10,\n",
    "            20,\n",
    "            30,\n",
    "            40,\n",
    "            -1,\n",
    "        ],  # missing scores are defined as -1\n",
    "        \"date\": [\n",
    "            datetime(2023, 1, 1),\n",
    "            datetime(2023, 2, 1),\n",
    "            datetime(2023, 3, 1),\n",
    "            datetime(2021, 1, 1),  # one date too old\n",
    "            datetime(2023, 5, 1),\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config Files\n",
    "We define our data quality rules within one or more YAML files (YAML is a mark-up langauge, similar to JSON, that was chosen because it is simple and human-readable (more so than JSON)).\n",
    "\n",
    "We will validate this file against the key-value pairs in our DataQualityConfig class.\n",
    "\n",
    "The YAML file (and DataQualityConfig class) has:\n",
    "1. Some overall settings for the measurement you are undertaking (all of which are optional)\n",
    "    1. dataset_name\n",
    "    2. dataset_id\n",
    "    2. measurement_sample\n",
    "    3. lifecycle_stage\n",
    "    4. measurement_time (if you want to override the default of 'now')\n",
    "2. A list of data quality rules, where each rule specififes:\n",
    "    1. The function you are calling (like 'uniqueness' or 'validity_regex')\n",
    "    2. The parameters of that function (like 'field' and 'regex_pattern')\n",
    "    The names are the same as the rules 'validity_regex' = ValidityRegexRule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T12:51:54.255708Z",
     "iopub.status.busy": "2025-09-18T12:51:54.255464Z",
     "iopub.status.idle": "2025-09-18T12:51:54.272621Z",
     "shell.execute_reply": "2025-09-18T12:51:54.271998Z"
    }
   },
   "outputs": [],
   "source": [
    "# We can find out the overall settings like this:\n",
    "DataQualityConfig.model_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T12:51:54.274982Z",
     "iopub.status.busy": "2025-09-18T12:51:54.274776Z",
     "iopub.status.idle": "2025-09-18T12:51:54.326312Z",
     "shell.execute_reply": "2025-09-18T12:51:54.325713Z"
    }
   },
   "outputs": [],
   "source": [
    "# within 'rules' the parameters will vary based on the function\n",
    "UniquenessRule.model_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T12:51:54.329830Z",
     "iopub.status.busy": "2025-09-18T12:51:54.329613Z",
     "iopub.status.idle": "2025-09-18T12:51:54.346422Z",
     "shell.execute_reply": "2025-09-18T12:51:54.345767Z"
    }
   },
   "outputs": [],
   "source": [
    "ValidityRegexRule.model_fields  # notice how this has an additional field of 'regex_pattern'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing this as a YAML file\n",
    "YAML files are written as key-value pairs (using a colon to separate the key from the value).\n",
    "Lists items are indicated with a single hyphen - \n",
    "\n",
    "### Example YAML file with 2 rules\n",
    "\n",
    "```yaml\n",
    "dataset_name: My Source Data\n",
    "measurement_sample: 10% of records\n",
    "lifecycle_stage: null # or you can just omit the entry if it's optional and null\n",
    "rules:\n",
    "- field: id\n",
    "  function: uniqueness\n",
    "- field: name\n",
    "  na_values: ''\n",
    "  function: validity_regex\n",
    "  regex_pattern: '[A-z0-9_]'\n",
    "```\n",
    "\n",
    "#### Writing lists\n",
    "There are two ways to write lists, as individual elements with '-' or like you would in python\n",
    "\n",
    "```yaml\n",
    "- field: category\n",
    "  function: accuracy\n",
    "  valid_values: [A,B,C,D] # simplest way\n",
    "  valid_values: ['A','B','C','D'] # equivalent - but the quotation marks for strings are not necessary\n",
    "  valid_values:\n",
    "  - A\n",
    "  - B\n",
    "  - C\n",
    "  - D\n",
    "  # most verbose way, but for long lists this might be preferable\n",
    "```\n",
    "\n",
    "#### Writing REGEX\n",
    "To ensure characters aren't escaped incorrectly, always surround regex_pattern with single quotation marks (')\n",
    "\n",
    "```yaml\n",
    "- field: your_field\n",
    "  function: validity_regex\n",
    "  regex_pattern: '[A-Za-z]+' #standard regex\n",
    "  regex_pattern: '\\d{4}-\\d{2}-\\d{2}' # if you use single quotes, you don't need to 'double escape' for special characters like \\d\n",
    "  regex_pattern: \"\\\\d{4}-\\\\d{2}-\\\\d{2}\" # this is more confusing; equivalent pattern if you surround your regex with double quotation marks (\") rather than single (')\n",
    "  regex_pattern: 'don''t' # if you need to use the single quotation mark as part of your pattern, you type it twice. This pattern matches the word \"don't\" \n",
    "\n",
    "```\n",
    " \n",
    "### Try it out yourself\n",
    "Complete the EXERCISE_rules.yaml, so that we have:\n",
    "- uniqueness rule running on the id field\n",
    "- completeness rule running on the name field\n",
    "- validity_regex rule running on the email field\n",
    "- accuracy rule running on the category field (with valid values of A,B,C,D)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T12:51:54.349761Z",
     "iopub.status.busy": "2025-09-18T12:51:54.349489Z",
     "iopub.status.idle": "2025-09-18T12:51:54.369814Z",
     "shell.execute_reply": "2025-09-18T12:51:54.369153Z"
    }
   },
   "outputs": [],
   "source": [
    "# this function will create a DataQualityConfig object from one or more yaml files\n",
    "dc_solution = DataQualityConfig.from_yaml(\"resources/SOLUTION_rules.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T12:51:54.372703Z",
     "iopub.status.busy": "2025-09-18T12:51:54.372439Z",
     "iopub.status.idle": "2025-09-18T12:51:54.391158Z",
     "shell.execute_reply": "2025-09-18T12:51:54.390506Z"
    }
   },
   "outputs": [],
   "source": [
    "# UNCOMMENT this line and run once you have tried the exercise\n",
    "# dc_exercise = DataQualityConfig.from_yaml(\"resources/EXERCISE_rules.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check your answers\n",
    "The below equality should give 'True', if it doesn't the cell below will print everything out side-by-side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T12:51:54.394027Z",
     "iopub.status.busy": "2025-09-18T12:51:54.393741Z",
     "iopub.status.idle": "2025-09-18T12:51:54.410626Z",
     "shell.execute_reply": "2025-09-18T12:51:54.410079Z"
    }
   },
   "outputs": [],
   "source": [
    "# dc_solution == dc_exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading YAML files\n",
    "You might find it useful to separate your data quality rules into sections, such as\n",
    "- 'biographical.yaml'\n",
    "- 'customer_data.yaml'\n",
    "\n",
    "or, as you create more rules, separate them into directories\n",
    "\n",
    "\n",
    "The pattern for loading these is:\n",
    "```python\n",
    "config = DataQualityConfig.from_yaml(['biographical.yaml', 'customer_data.yaml'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the rules against your data\n",
    "Once you've loaded a DataQualityConfig object, you can run that against a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T12:51:54.459443Z",
     "iopub.status.busy": "2025-09-18T12:51:54.459235Z",
     "iopub.status.idle": "2025-09-18T12:51:54.481750Z",
     "shell.execute_reply": "2025-09-18T12:51:54.481249Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import UTC\n",
    "\n",
    "dc_solution.measurement_sample = \"Our Test Data\"\n",
    "dc_solution.dataset_name = \"Overwrite Dataset Name\"\n",
    "dc_solution.measurement_time = datetime.now(tz=UTC)\n",
    "report = dc_solution.execute(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T12:51:54.484097Z",
     "iopub.status.busy": "2025-09-18T12:51:54.483892Z",
     "iopub.status.idle": "2025-09-18T12:51:54.511262Z",
     "shell.execute_reply": "2025-09-18T12:51:54.510571Z"
    }
   },
   "outputs": [],
   "source": [
    "report.to_dataframe(measurement_time_format=\"%Y-%m-%d %H:%M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving your rules from the Data Quality Report\n",
    "A useful workflow is to iterate on rules in a notebook to create a draft data quality report,\n",
    "then, once you've settled on the rules you want to run, you want to pull out those rules into a YAML file so you can deploy into a production setting. This can be a faster or more convenient way of writing that yaml file from scratch.\n",
    "\n",
    "You can then tweak / edit the YAML file to suit\n",
    "\n",
    "Note: if you overwrite the default rule_description values into your YAML file, then this two-way conversion won't work for those rules (they will be skipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T12:51:54.514431Z",
     "iopub.status.busy": "2025-09-18T12:51:54.514213Z",
     "iopub.status.idle": "2025-09-18T12:51:54.533955Z",
     "shell.execute_reply": "2025-09-18T12:51:54.533322Z"
    }
   },
   "outputs": [],
   "source": [
    "report = dc_solution.execute(\n",
    "    df\n",
    ")  # let's remove the overwritten values and get a fresh report\n",
    "config_from_report = DataQualityConfig.from_report(report)\n",
    "# we can recover the data quality config from a DataQualityReport\n",
    "# but ONLY if the rule_description is left in the default state (which is a dictionary of all parameters)\n",
    "dc_solution == config_from_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving your rules to a YAML file\n",
    "To avoid writing out the YAML file by hand, you can write a DataQualityConfig to a yaml file.\n",
    "Note that it will output all rules, but only output the first values for the measurement information (source_data, measurement_sample etc).\n",
    "\n",
    "It will tend to output a more verbose YAML file than you need, for example if a value is 'null' it will output that to the YAML file (rather than ignoring it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T12:51:54.536681Z",
     "iopub.status.busy": "2025-09-18T12:51:54.536268Z",
     "iopub.status.idle": "2025-09-18T12:51:54.556105Z",
     "shell.execute_reply": "2025-09-18T12:51:54.555506Z"
    }
   },
   "outputs": [],
   "source": [
    "config_from_report.to_yaml(\"resources/yaml_from_report.yaml\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing your Regular Expressions\n",
    "It can be easiser to manage your regular expressions in one place, especially if you use lots of them.\n",
    "\n",
    "We provide a pattern for that:\n",
    "```python\n",
    "DataQualityConfig.from_yaml('my_config.yaml', regex_yaml_path='my_regex_patterns.yaml')\n",
    "``` \n",
    "\n",
    "This assumes your regex file looks like this:\n",
    "```yaml\n",
    "EMAIL_REGEX: '[a-Z...regex here]'\n",
    "PHONE_REGEX: '[0-9]+'\n",
    "```\n",
    "\n",
    "and it will swap out the values for EMAIL_REGEX etc in your config file, which can look like this:\n",
    "\n",
    "```yaml\n",
    "- field: email\n",
    "  function: validity_regex\n",
    "  regex_pattern: EMAIL_REGEX\n",
    "```\n",
    "\n",
    "We provide a simple regex_patterns.yaml file for you to try\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T12:51:54.558662Z",
     "iopub.status.busy": "2025-09-18T12:51:54.558449Z",
     "iopub.status.idle": "2025-09-18T12:51:54.578114Z",
     "shell.execute_reply": "2025-09-18T12:51:54.576901Z"
    }
   },
   "outputs": [],
   "source": [
    "config_without_swap = DataQualityConfig.from_yaml(\n",
    "    \"resources/SOLUTION_rules_with_regex.yaml\"\n",
    ")\n",
    "print(\n",
    "    f\"The regex_pattern in the YAML file is this: {config_without_swap.rules[3].regex_pattern}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T12:51:54.581891Z",
     "iopub.status.busy": "2025-09-18T12:51:54.581547Z",
     "iopub.status.idle": "2025-09-18T12:51:54.601391Z",
     "shell.execute_reply": "2025-09-18T12:51:54.600789Z"
    }
   },
   "outputs": [],
   "source": [
    "config_with_regex_swap = DataQualityConfig.from_yaml(\n",
    "    \"resources/SOLUTION_rules_with_regex.yaml\",\n",
    "    regex_yaml_path=\"resources/regex_patterns.yaml\",\n",
    ")\n",
    "print(\n",
    "    f\"EMAIL_REGEX gets swapped if we pass a regex YAML file to: {config_with_regex_swap.rules[3].regex_pattern}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then run this swapped config against your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T12:51:54.604107Z",
     "iopub.status.busy": "2025-09-18T12:51:54.603891Z",
     "iopub.status.idle": "2025-09-18T12:51:54.632634Z",
     "shell.execute_reply": "2025-09-18T12:51:54.631835Z"
    }
   },
   "outputs": [],
   "source": [
    "config_with_regex_swap.execute(df).to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing the number of output samples and invalid row numbers\n",
    "These are controlled with global settings (default is 10)\n",
    "\n",
    "```python\n",
    "from gchq_data_quality.globals import SampleConfig\n",
    "SampleConfig.RECORDS_FAILED_SAMPLE_SIZE = 25\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gchq-data-quality",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
